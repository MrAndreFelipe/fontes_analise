# üìö DOCUMENTA√á√ÉO T√âCNICA COMPLETA - Sistema RAG Cativa T√™xtil

## PARTE 2: M√≥dulos Core, Seguran√ßa LGPD e Processamento de Dados

---

# 4. M√ìDULOS CORE

Os m√≥dulos core s√£o a **funda√ß√£o** do sistema, fornecendo funcionalidades essenciais que todos os outros componentes utilizam.

---

## 4.1. Config (Configura√ß√£o Centralizada)

**Arquivo:** `src/core/config.py`

### **O que faz?**
- Carrega vari√°veis de ambiente do `.env`
- Centraliza todas as configura√ß√µes do sistema
- Usa padr√£o Singleton (uma inst√¢ncia compartilhada)
- Valida configura√ß√µes obrigat√≥rias

### **Como funciona?**

```python
# 1. Carrega .env automaticamente ao importar
from dotenv import load_dotenv
load_dotenv()  # Carrega .env ‚Üí os.environ

# 2. Define dataclasses para cada grupo de config
@dataclass
class OracleConfig:
    host: str
    port: int
    user: str
    password: str
    service_name: Optional[str] = None
    sid: Optional[str] = None
    
    @classmethod
    def from_env(cls):
        """Carrega do os.environ"""
        return cls(
            host=os.getenv('ORACLE_HOST', 'localhost'),
            port=int(os.getenv('ORACLE_PORT', '1521')),
            # ... demais campos
        )

# 3. Classe Config (singleton)
class Config:
    _oracle_config = None  # Cache (singleton)
    
    @classmethod
    def oracle(cls) -> OracleConfig:
        """Retorna config Oracle (cached)"""
        if cls._oracle_config is None:
            cls._oracle_config = OracleConfig.from_env()
        return cls._oracle_config
```

### **Por que Singleton?**
- **Carrega vari√°veis UMA VEZ** na inicializa√ß√£o
- **Reutiliza mesma inst√¢ncia** em todo o c√≥digo
- **Evita ler `.env` m√∫ltiplas vezes** (performance)
- **Garante consist√™ncia** das configs

### **Uso no c√≥digo:**

```python
from core.config import Config

# Acessar Oracle
oracle = Config.oracle()
print(f"Host: {oracle.host}:{oracle.port}")
print(f"User: {oracle.user}")

# Acessar PostgreSQL
postgres = Config.postgres()
conn_string = f"postgresql://{postgres.user}:{postgres.password}@{postgres.host}:{postgres.port}/{postgres.database}"

# Acessar OpenAI
openai = Config.openai()
client = OpenAI(api_key=openai.api_key)

# Acessar Evolution API (WhatsApp)
evolution = Config.evolution()
webhook_url = f"{evolution.webhook_public_url}/webhook"
```

### **Configura√ß√µes Fixas (Constantes):**

```python
class Config:
    # Chunking
    MAX_CHUNK_TOKENS = 800       # M√°ximo tokens por chunk
    OVERLAP_TOKENS = 100         # Sobreposi√ß√£o entre chunks
    MIN_CHUNK_TOKENS = 120       # M√≠nimo (menores s√£o consolidados)
    
    # Embeddings
    EMBEDDING_DIMENSION = 1536   # text-embedding-3-small
    
    # LGPD
    LGPD_LEVELS = ["BAIXO", "M√âDIO", "ALTO"]
    
    # Processamento
    BATCH_SIZE = 1000            # Registros por lote
```

**Por que essas constantes?**
- **MAX_CHUNK_TOKENS = 800:** Limite do contexto GPT-4 (4096 tokens) dividido em ~5 chunks
- **OVERLAP_TOKENS = 100:** Evita perda de contexto entre chunks (overlap sem√¢ntico)
- **EMBEDDING_DIMENSION = 1536:** Dimens√£o fixa do modelo OpenAI `text-embedding-3-small`

---

## 4.2. Connection Pool (Gerenciamento de Conex√µes)

**Arquivo:** `src/core/connection_pool.py`

### **O que faz?**
Gerencia **pools de conex√µes** para PostgreSQL e Oracle, permitindo:
- Reutiliza√ß√£o de conex√µes (performance)
- Limite de conex√µes simult√¢neas (evita esgotar recursos)
- Gerenciamento autom√°tico do ciclo de vida
- Thread-safe (m√∫ltiplas threads podem usar simultaneamente)

### **Por que Connection Pool?**

**SEM Pool (‚ùå Ruim):**
```python
# Cada consulta abre/fecha conex√£o
for i in range(1000):
    conn = psycopg2.connect(...)  # ‚ùå Lento (TCP handshake)
    cursor = conn.cursor()
    cursor.execute("SELECT ...")
    conn.close()                  # ‚ùå Desperdi√ßa recurso
```
- **Problema:** Abrir/fechar conex√£o √© LENTO (~50-100ms por conex√£o)
- **Problema:** Esgota recursos do banco (limite de conex√µes)

**COM Pool (‚úÖ Bom):**
```python
# Pool mant√©m 2-10 conex√µes abertas
pool = DatabaseConnectionPool(min=2, max=10)

for i in range(1000):
    conn = pool.get_connection()  # ‚úÖ R√°pido (conex√£o j√° aberta)
    cursor = conn.cursor()
    cursor.execute("SELECT ...")
    pool.return_connection(conn)  # ‚úÖ Reutiliza
```
- **Benef√≠cio:** Conex√µes j√° est√£o abertas (< 1ms)
- **Benef√≠cio:** Reutiliza at√© 10 conex√µes simult√¢neas
- **Benef√≠cio:** Limite controlado (n√£o esgota banco)

### **Como funciona?**

#### **Inicializa√ß√£o:**

```python
class DatabaseConnectionPool:
    def __init__(self, 
                 postgres_config: Dict,
                 oracle_config: Dict,
                 min_connections: int = 2,
                 max_connections: int = 10):
        
        # PostgreSQL Pool (psycopg2.pool.ThreadedConnectionPool)
        if postgres_config:
            self.postgres_pool = pool.ThreadedConnectionPool(
                minconn=min_connections,   # Mant√©m 2 conex√µes sempre abertas
                maxconn=max_connections,   # M√°ximo de 10 conex√µes simult√¢neas
                host=postgres_config['host'],
                port=postgres_config['port'],
                database=postgres_config['database'],
                user=postgres_config['user'],
                password=postgres_config['password']
            )
        
        # Oracle Pool (cx_Oracle.SessionPool)
        if oracle_config:
            dsn = cx_Oracle.makedsn(
                oracle_config['host'],
                oracle_config['port'],
                service_name=oracle_config['service_name']
            )
            
            self.oracle_pool = cx_Oracle.SessionPool(
                user=oracle_config['user'],
                password=oracle_config['password'],
                dsn=dsn,
                min=min_connections,       # M√≠nimo 2 sess√µes
                max=max_connections,       # M√°ximo 10 sess√µes
                increment=1,               # Incrementa de 1 em 1
                threaded=True,             # Thread-safe
                getmode=cx_Oracle.SPOOL_ATTRVAL_NOWAIT  # Retorna erro se pool cheio
            )
```

**Por que `ThreadedConnectionPool`?**
- Permite m√∫ltiplas threads usarem o pool simultaneamente
- Cada thread obt√©m sua pr√≥pria conex√£o do pool
- Thread-safe via locks internos

**Por que `SPOOL_ATTRVAL_NOWAIT`?**
- Se pool estiver cheio (10 conex√µes em uso), **retorna erro** imediatamente
- Alternativa seria esperar (bloquear thread)
- Erro √© melhor: permite retry com backoff

#### **Uso do Pool:**

**M√©todo 1: Manual (get/return)**
```python
pool = DatabaseConnectionPool(...)

# Obter conex√£o
conn = pool.get_postgres_connection()

try:
    # Usar conex√£o
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM chunks LIMIT 10")
    results = cursor.fetchall()
finally:
    # SEMPRE retornar ao pool
    pool.return_postgres_connection(conn)
```

**M√©todo 2: Context Manager (recomendado)**
```python
pool = DatabaseConnectionPool(...)

# Context manager garante retorno autom√°tico
with pool.postgres_connection() as conn:
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM chunks LIMIT 10")
    results = cursor.fetchall()
# Conex√£o retorna automaticamente ao pool aqui
```

**Por que Context Manager √© melhor?**
- Garante retorno **mesmo se exception ocorrer**
- C√≥digo mais limpo (sem try/finally)
- Padr√£o Python (Pythonic)

#### **Retry Autom√°tico:**

```python
@retry_database(max_retries=3)
def get_postgres_connection(self):
    """Obt√©m conex√£o COM RETRY autom√°tico"""
    conn = self.postgres_pool.getconn()
    return conn
```

**O que o decorator `@retry_database` faz?**
- Se falhar (timeout, connection error), **tenta novamente** at√© 3 vezes
- Usa **exponential backoff**: 0.5s ‚Üí 1s ‚Üí 2s
- Log de cada tentativa
- S√≥ falha ap√≥s esgotar retries

---

## 4.3. Retry Handler (L√≥gica de Retry)

**Arquivo:** `src/core/retry_handler.py`

### **O que faz?**
Implementa **l√≥gica de retry** com exponential backoff para opera√ß√µes que podem falhar temporariamente:
- Conex√µes de banco (timeouts, deadlocks)
- Chamadas API OpenAI (rate limits, erros 5xx)
- Requisi√ß√µes HTTP (network errors)

### **Por que Retry?**

**Problema:** Erros tempor√°rios s√£o comuns:
- Oracle timeout (banco ocupado)
- OpenAI rate limit (quota excedida)
- Network glitch (packet loss)

**Solu√ß√£o:** Retry com backoff exponencial:
```
Tentativa 1: Falha ‚Üí Aguarda 0.5s
Tentativa 2: Falha ‚Üí Aguarda 1.0s (2x)
Tentativa 3: Falha ‚Üí Aguarda 2.0s (2x)
Tentativa 4: Sucesso ‚úÖ
```

### **Como funciona?**

#### **Decorator B√°sico:**

```python
def retry_with_backoff(max_retries=3,
                      initial_delay=0.5,
                      backoff_factor=2.0,
                      exceptions=(Exception,)):
    """
    Decorator para retry com exponential backoff
    
    Args:
        max_retries: M√°ximo de tentativas (al√©m da primeira)
        initial_delay: Delay inicial em segundos
        backoff_factor: Fator de multiplica√ß√£o do delay
        exceptions: Tupla de exce√ß√µes a tratar
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            delay = initial_delay
            last_exception = None
            
            for attempt in range(max_retries + 1):
                try:
                    result = func(*args, **kwargs)
                    
                    if attempt > 0:
                        logger.info(f"{func.__name__} succeeded after {attempt + 1} attempts")
                    
                    return result
                
                except exceptions as e:
                    last_exception = e
                    
                    if attempt < max_retries:
                        logger.warning(
                            f"{func.__name__} failed (attempt {attempt + 1}/{max_retries + 1}): {e}. "
                            f"Retrying in {delay}s..."
                        )
                        time.sleep(delay)
                        delay *= backoff_factor  # Exponential backoff
                    else:
                        logger.error(f"{func.__name__} failed after {max_retries + 1} attempts: {e}")
            
            raise last_exception
        
        return wrapper
    return decorator
```

#### **Uso:**

```python
# Retry para banco de dados
@retry_database(max_retries=3)
def get_oracle_connection():
    return cx_Oracle.connect(...)

# Retry para OpenAI
@retry_openai(max_retries=3)
def generate_embedding(text):
    return openai.embeddings.create(...)

# Retry para HTTP
@retry_api_call(max_retries=3)
def send_whatsapp_message(phone, message):
    return requests.post(...)
```

#### **Strategies Pr√©-definidas:**

**`retry_database` (PostgreSQL + Oracle):**
```python
def retry_database(max_retries=3):
    """
    Retry para opera√ß√µes de banco
    
    Trata:
    - Timeouts
    - Connection errors
    - Deadlocks
    """
    import psycopg2
    import cx_Oracle
    
    db_exceptions = (
        psycopg2.OperationalError,
        psycopg2.InterfaceError,
        cx_Oracle.DatabaseError,
        ConnectionError,
        TimeoutError
    )
    
    return retry_with_backoff(
        max_retries=max_retries,
        initial_delay=0.5,         # Come√ßa com 0.5s
        backoff_factor=2.0,        # Dobra a cada tentativa
        exceptions=db_exceptions
    )
```

**`retry_openai` (OpenAI API):**
```python
def retry_openai(max_retries=3):
    """
    Retry para OpenAI API
    
    Trata:
    - Rate limits (429)
    - API errors (5xx)
    - Timeouts
    """
    from openai import (
        APIError,
        APIConnectionError,
        RateLimitError,
        APITimeoutError
    )
    
    openai_exceptions = (
        APIError,
        APIConnectionError,
        RateLimitError,
        APITimeoutError,
        TimeoutError,
        ConnectionError
    )
    
    return retry_with_backoff(
        max_retries=max_retries,
        initial_delay=2.0,         # OpenAI precisa delay maior
        backoff_factor=3.0,        # Backoff mais agressivo (2s ‚Üí 6s ‚Üí 18s)
        exceptions=openai_exceptions
    )
```

**Por que delays diferentes?**
- **Banco:** Timeout geralmente √© r√°pido (< 1s) ‚Üí delay menor
- **OpenAI:** Rate limit pode durar v√°rios segundos ‚Üí delay maior

---

## 4.4. Rate Limiter (Controle de Taxa)

**Arquivo:** `src/core/rate_limiter.py`

### **O que faz?**
Previne **abuso** do sistema limitando n√∫mero de requisi√ß√µes por usu√°rio:
- M√°ximo X mensagens por minuto
- M√°ximo Y mensagens por hora
- Bloqueia temporariamente se exceder

### **Por que Rate Limiter?**

**Problema sem rate limit:**
- Usu√°rio envia 1000 mensagens em 1 minuto
- Sistema fica sobrecarregado
- Banco de dados esgota conex√µes
- OpenAI API quota esgotada
- Custo alto (cada query = $$$)

**Solu√ß√£o com rate limit:**
- M√°ximo 10 mensagens/minuto
- M√°ximo 100 mensagens/hora
- Bloqueia usu√°rio por 1 hora se exceder

### **Como funciona?**

```python
class RateLimiter:
    """
    Rate limiter baseado em sliding window
    """
    
    def __init__(self,
                 max_requests_per_minute: int = 10,
                 max_requests_per_hour: int = 100):
        self.max_per_minute = max_requests_per_minute
        self.max_per_hour = max_requests_per_hour
        
        # Armazena timestamps das requisi√ß√µes por usu√°rio
        # {user_id: [timestamp1, timestamp2, ...]}
        self.user_requests = {}
    
    def is_allowed(self, user_id: str) -> bool:
        """
        Verifica se usu√°rio pode fazer requisi√ß√£o
        
        Returns:
            True se permitido, False se bloqueado
        """
        now = time.time()
        
        # Inicializa lista se primeira requisi√ß√£o
        if user_id not in self.user_requests:
            self.user_requests[user_id] = []
        
        # Remove timestamps antigos (> 1 hora)
        user_timestamps = self.user_requests[user_id]
        user_timestamps = [ts for ts in user_timestamps if now - ts < 3600]
        self.user_requests[user_id] = user_timestamps
        
        # Conta requisi√ß√µes no √∫ltimo minuto
        last_minute = [ts for ts in user_timestamps if now - ts < 60]
        
        # Verifica limites
        if len(last_minute) >= self.max_per_minute:
            logger.warning(f"User {user_id} exceeded per-minute limit ({self.max_per_minute})")
            return False
        
        if len(user_timestamps) >= self.max_per_hour:
            logger.warning(f"User {user_id} exceeded per-hour limit ({self.max_per_hour})")
            return False
        
        # Adiciona timestamp atual
        user_timestamps.append(now)
        return True
```

**Por que Sliding Window?**
- Mais justo que fixed window
- Evita burst no in√≠cio da janela

**Exemplo:**
```
Fixed Window (ruim):
00:00 - 01:00: 100 requests ‚úÖ
01:00 - 02:00: 100 requests ‚úÖ
Total em 1 minuto (00:59 - 01:00): 200 requests ‚ùå Burst!

Sliding Window (bom):
Qualquer janela de 1 hora: m√°ximo 100 requests
```

### **Uso no Message Handler:**

```python
class MessageHandler:
    def __init__(self):
        self.rate_limiter = RateLimiter(
            max_requests_per_minute=10,
            max_requests_per_hour=100
        )
    
    def handle_webhook_payload(self, payload):
        user_id = payload['from']
        
        # Verifica rate limit
        if not self.rate_limiter.is_allowed(user_id):
            return {
                'error': 'Rate limit exceeded',
                'message': 'Voc√™ excedeu o limite de requisi√ß√µes. Tente novamente mais tarde.'
            }
        
        # Processa mensagem normalmente
        return self.process_message(payload)
```

---

# 5. SEGURAN√áA E LGPD

## 5.1. Criptografia AES-256-GCM

**Arquivo:** `src/security/encryption.py`

### **O que faz?**
Implementa **criptografia AES-256-GCM** para proteger dados sens√≠veis (CNPJ, CPF, nomes) em conformidade com **LGPD Art. 46**.

### **Por que AES-256-GCM?**

| **Aspecto** | **AES-256-GCM** | **Por que √© importante?** |
|------------|-----------------|--------------------------|
| **AES-256** | Algoritmo de criptografia com chave de 256 bits | Padr√£o NIST (governo EUA), inquebr√°vel com tecnologia atual |
| **GCM Mode** | Galois/Counter Mode | Autentica√ß√£o integrada (detecta adultera√ß√£o) |
| **Tag de Autentica√ß√£o** | 16 bytes | Garante integridade (se alterado, falha na descriptografia) |
| **IV √∫nico** | 12 bytes gerados aleatoriamente | Mesmo texto criptografado 2x gera resultados diferentes |

### **Como funciona?**

#### **Estrutura do Dado Criptografado:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ IV (12B) ‚îÇ Ciphertext (nB) ‚îÇ Tag (16B)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

IV (Initialization Vector):
- 12 bytes aleat√≥rios
- √önico para cada opera√ß√£o
- Necess√°rio para descriptografar

Ciphertext:
- Tamanho vari√°vel (depende do texto)
- Texto original criptografado

Tag:
- 16 bytes de autentica√ß√£o
- Gerado automaticamente pelo GCM
- Valida integridade dos dados
```

#### **Gera√ß√£o da Chave:**

```python
# scripts/generate_encryption_key.py

import secrets
import base64

# Gera 32 bytes aleat√≥rios (256 bits)
key = secrets.token_bytes(32)

# Codifica em base64 para facilitar armazenamento
key_b64 = base64.b64encode(key).decode('ascii')

print(f"ENCRYPTION_KEY={key_b64}")
# Output: ENCRYPTION_KEY=j3Oa2LhtM3BkYzFm4R2V... (44 caracteres)
```

**Por que 32 bytes = 256 bits?**
- AES-256 requer chave de exatamente 256 bits
- 1 byte = 8 bits ‚Üí 32 bytes √ó 8 = 256 bits

**Por que base64?**
- Base64 permite armazenar bytes como string ASCII
- F√°cil de copiar/colar no `.env`
- 32 bytes ‚Üí 44 caracteres base64

#### **Criptografar:**

```python
class AES256Encryptor:
    def encrypt(self, plaintext: str) -> bytes:
        """
        Criptografa texto
        
        Args:
            plaintext: Texto em portugu√™s (UTF-8)
        
        Returns:
            bytes: IV + Ciphertext + Tag
        """
        # 1. Gera IV √∫nico (12 bytes aleat√≥rios)
        iv = os.urandom(12)
        
        # 2. Converte texto para bytes UTF-8
        plaintext_bytes = plaintext.encode('utf-8')
        
        # 3. Criptografa com AES-256-GCM
        # Retorna: ciphertext + tag (tag √© automaticamente inclu√≠da)
        ciphertext_and_tag = self.cipher.encrypt(iv, plaintext_bytes, None)
        
        # 4. Retorna: IV + (Ciphertext + Tag)
        return iv + ciphertext_and_tag
```

**Exemplo:**
```python
encryptor = AES256Encryptor()

plaintext = "CNPJ: 03.221.721/0001-10"  # 28 caracteres UTF-8
encrypted = encryptor.encrypt(plaintext)

# Tamanhos:
# IV:         12 bytes
# Ciphertext: 28 bytes (mesmo tamanho do texto)
# Tag:        16 bytes
# Total:      56 bytes
```

#### **Descriptografar:**

```python
def decrypt(self, encrypted_data: bytes) -> str:
    """
    Descriptografa dados
    
    Args:
        encrypted_data: IV + Ciphertext + Tag
    
    Returns:
        str: Texto original
    
    Raises:
        ValueError: Se dados inv√°lidos ou adulterados
    """
    # 1. Separa IV (primeiros 12 bytes)
    iv = encrypted_data[:12]
    
    # 2. Pega ciphertext + tag (restante)
    ciphertext_and_tag = encrypted_data[12:]
    
    # 3. Descriptografa E valida tag
    # Se tag inv√°lida ‚Üí InvalidTag exception (dados adulterados!)
    plaintext_bytes = self.cipher.decrypt(iv, ciphertext_and_tag, None)
    
    # 4. Converte bytes ‚Üí string UTF-8
    plaintext = plaintext_bytes.decode('utf-8')
    
    return plaintext
```

**Por que a tag √© importante?**
- **Integridade:** Se 1 bit for alterado, tag fica inv√°lida
- **Autentica√ß√£o:** Garante que dados vieram da fonte correta
- **Seguran√ßa:** Previne ataques de modifica√ß√£o

**Exemplo de adultera√ß√£o:**
```python
encryptor = AES256Encryptor()

# Criptografa
original = "Dados sens√≠veis"
encrypted = encryptor.encrypt(original)

# Adultera 1 byte
encrypted_tampered = encrypted[:-1] + b'\x00'

# Tenta descriptografar
try:
    decrypted = encryptor.decrypt(encrypted_tampered)
except ValueError:
    print("‚ùå Dados foram adulterados!")  # ‚úÖ Detectado!
```

### **Uso no Sistema:**

#### **Criptografar ao sincronizar (oracle_sync.py):**

```python
class OracleToPostgreSQLSync:
    def _encrypt_if_needed(self, content: str, nivel_lgpd: str) -> Optional[bytes]:
        """
        Criptografa chunks sens√≠veis
        
        Pol√≠tica:
        - ALTO: Criptografa (CPF, CNPJ, dados pessoais)
        - M√âDIO: Criptografa (dados financeiros sens√≠veis)
        - BAIXO: N√ÉO criptografa (dados agregados/p√∫blicos)
        """
        if not self.encryptor:
            return None
        
        # S√≥ criptografa ALTO ou M√âDIO
        if nivel_lgpd not in ['ALTO', 'M√âDIO', 'MEDIO']:
            return None
        
        try:
            encrypted_bytes = self.encryptor.encrypt(content)
            logger.debug(f"Chunk criptografado: LGPD={nivel_lgpd}, size={len(encrypted_bytes)} bytes")
            return encrypted_bytes
        except Exception as e:
            logger.error(f"Erro ao criptografar: {e}")
            return None
    
    def sync_textual_data(self):
        for row in oracle_data:
            # Classifica LGPD
            nivel_lgpd = row['nivel_lgpd']  # ALTO, M√âDIO ou BAIXO
            
            # Criptografa se necess√°rio
            encrypted_content = self._encrypt_if_needed(row['texto_completo'], nivel_lgpd)
            
            # Insere no PostgreSQL
            chunk_data = {
                'content_text': row['texto_completo'],        # Texto original (sempre)
                'encrypted_content': encrypted_content,       # Vers√£o criptografada (s√≥ se ALTO/M√âDIO)
                'nivel_lgpd': nivel_lgpd
            }
            self.postgres_adapter.insert_chunk(chunk_data)
```

#### **Descriptografar ao buscar (rag_engine.py):**

```python
class RAGEngine:
    def _decrypt_if_needed(self, chunks: List[Dict]) -> List[Dict]:
        """
        Descriptografa chunks que possuem encrypted_content
        """
        for chunk in chunks:
            # Se tem vers√£o criptografada, descriptografa
            if chunk.get('encrypted_content'):
                try:
                    decrypted = self.encryptor.decrypt(chunk['encrypted_content'])
                    chunk['content_text'] = decrypted
                    logger.debug(f"Chunk {chunk['chunk_id']} descriptografado")
                except Exception as e:
                    logger.error(f"Erro ao descriptografar chunk {chunk['chunk_id']}: {e}")
                    # Mant√©m texto original se falhar
        
        return chunks
    
    def _embedding_search(self, query: str, limit: int = 5):
        # Busca chunks similares
        chunks = self._vector_search(query, limit)
        
        # Descriptografa se necess√°rio
        chunks = self._decrypt_if_needed(chunks)
        
        return chunks
```

### **Boas Pr√°ticas:**

‚úÖ **O que fazer:**
- Gerar chave com `secrets.token_bytes(32)` (criptograficamente seguro)
- Armazenar chave no `.env` (N√ÉO versionar!)
- Em produ√ß√£o: usar AWS Secrets Manager ou Azure Key Vault
- Criptografar dados **ANTES** de inserir no banco
- Descriptografar apenas quando **realmente necess√°rio**

‚ùå **O que N√ÉO fazer:**
- Usar chave hard-coded no c√≥digo
- Reutilizar IV (initialization vector)
- Armazenar chave no banco de dados
- Compartilhar chave por email/chat
- Commitar `.env` no Git

---

## 5.2. Auditoria LGPD (Logs de Acesso e Exclus√£o)

**Arquivo:** `src/security/lgpd_audit.py`

### **O que faz?**
Registra **logs de auditoria** para conformidade LGPD:
- **Art. 37¬∫:** Log de todos os acessos a dados pessoais
- **Art. 18¬∫:** Log de todas as exclus√µes de dados

### **Por que auditar?**
- **LGPD obriga** registro de acessos a dados pessoais
- Permite **rastreabilidade** (quem acessou o qu√™ e quando)
- Suporta **investiga√ß√µes** em caso de incidente
- Evid√™ncia para **√≥rg√£os reguladores** (ANPD)

### **Como funciona?**

#### **Log de Acesso (Art. 37¬∫):**

```python
class LGPDAuditLogger:
    def log_access(self,
                   user_id: str,                  # Telefone WhatsApp
                   user_name: Optional[str],      # Nome do usu√°rio
                   user_clearance: str,           # ALTO, M√âDIO, BAIXO
                   query_text: str,               # Pergunta do usu√°rio
                   query_classification: str,     # Classifica√ß√£o LGPD da query
                   route_used: str,               # text_to_sql, embeddings, cache
                   chunks_accessed: List[str],    # IDs dos chunks acessados
                   success: bool,                 # Se acesso foi bem-sucedido
                   denied_reason: Optional[str],  # Motivo se negado
                   processing_time_ms: int):      # Tempo de processamento
        """
        Registra acesso na tabela access_log
        """
        cursor = self.conn.cursor()
        
        query = """
            INSERT INTO access_log 
            (user_id, user_name, user_clearance, query_text, query_classification,
             route_used, chunks_accessed, success, denied_reason, processing_time_ms)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        
        cursor.execute(query, (
            user_id,
            user_name,
            user_clearance,
            query_text[:1000],  # Limita tamanho
            query_classification,
            route_used,
            chunks_accessed,    # Array PostgreSQL
            success,
            denied_reason,
            processing_time_ms
        ))
        
        self.conn.commit()
```

**Exemplo de uso:**
```python
audit_logger = LGPDAuditLogger(postgres_conn)

# Registra acesso bem-sucedido
audit_logger.log_access(
    user_id="+5547999887766",
    user_name="Jo√£o Silva",
    user_clearance="M√âDIO",
    query_text="Qual o total de vendas de outubro?",
    query_classification="M√âDIO",
    route_used="text_to_sql",
    chunks_accessed=[],  # SQL direto, sem chunks
    success=True,
    denied_reason=None,
    processing_time_ms=1234
)

# Registra acesso negado
audit_logger.log_access(
    user_id="+5547999887766",
    user_name="Jo√£o Silva",
    user_clearance="BAIXO",
    query_text="Me mostre CNPJs dos clientes",
    query_classification="ALTO",
    route_used="error",
    chunks_accessed=[],
    success=False,
    denied_reason="Clearance insuficiente: BAIXO < ALTO",
    processing_time_ms=12
)
```

**Consulta de logs:**
```sql
-- Acessos do √∫ltimo m√™s
SELECT 
    accessed_at,
    user_name,
    user_clearance,
    query_classification,
    route_used,
    success
FROM access_log
WHERE accessed_at >= NOW() - INTERVAL '30 days'
ORDER BY accessed_at DESC;

-- Acessos negados
SELECT 
    accessed_at,
    user_name,
    query_text,
    denied_reason
FROM access_log
WHERE success = FALSE
ORDER BY accessed_at DESC;
```

#### **Log de Exclus√£o (Art. 18¬∫):**

```python
def log_deletion(self,
                deletion_type: str,              # retention_cleanup, erasure_request, manual
                affected_table: str,             # chunks, access_log, etc
                records_deleted: int,            # Quantidade deletada
                deletion_reason: str,            # Motivo
                criteria_used: Dict,             # Crit√©rios (JSON)
                requested_by: str,               # Quem solicitou
                approved_by: Optional[str],      # Quem aprovou
                evidence_backup_location: str):  # Local do backup
    """
    Registra exclus√£o na tabela lgpd_deletion_log
    """
    cursor = self.conn.cursor()
    
    query = """
        INSERT INTO lgpd_deletion_log
        (deletion_type, affected_table, records_deleted, deletion_reason,
         criteria_used, requested_by, approved_by, evidence_backup_location)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
        RETURNING id
    """
    
    cursor.execute(query, (
        deletion_type,
        affected_table,
        records_deleted,
        deletion_reason,
        json.dumps(criteria_used),  # JSON
        requested_by,
        approved_by,
        evidence_backup_location
    ))
    
    log_id = cursor.fetchone()[0]
    self.conn.commit()
    
    return log_id
```

**Exemplo de uso:**
```python
# Limpeza autom√°tica por reten√ß√£o
audit_logger.log_deletion(
    deletion_type="retention_cleanup",
    affected_table="chunks",
    records_deleted=1523,
    deletion_reason="Dados com mais de 5 anos (pol√≠tica de reten√ß√£o)",
    criteria_used={
        "created_at_before": "2020-01-01",
        "nivel_lgpd": "ALTO",
        "retention_days": 1825  # 5 anos
    },
    requested_by="system",
    approved_by="auto",
    evidence_backup_location="/backups/2025-11-04_retention_cleanup.sql"
)

# Solicita√ß√£o de exclus√£o de titular
audit_logger.log_deletion(
    deletion_type="erasure_request",
    affected_table="chunks",
    records_deleted=42,
    deletion_reason="Solicita√ß√£o de exclus√£o do titular CNPJ 03.221.721/0001-10",
    criteria_used={
        "cnpj": "03221721000110",
        "data_category": "vendas"
    },
    requested_by="juridico@cativa.com.br",
    approved_by="dpo@cativa.com.br",
    evidence_backup_location="/backups/erasure/cnpj_03221721000110.sql"
)
```

**Consulta de exclus√µes:**
```sql
-- Exclus√µes dos √∫ltimos 90 dias
SELECT 
    executed_at,
    deletion_type,
    affected_table,
    records_deleted,
    deletion_reason
FROM lgpd_deletion_log
WHERE executed_at >= NOW() - INTERVAL '90 days'
ORDER BY executed_at DESC;

-- Total deletado por tipo
SELECT 
    deletion_type,
    COUNT(*) as total_operations,
    SUM(records_deleted) as total_records
FROM lgpd_deletion_log
GROUP BY deletion_type;
```

---

**CONTINUA NA PARTE 3...**

*Este √© o Documento Parte 2 de 3*  
*Pr√≥ximo: RAG Engine, Text-to-SQL, WhatsApp Integration, Fluxos End-to-End*
